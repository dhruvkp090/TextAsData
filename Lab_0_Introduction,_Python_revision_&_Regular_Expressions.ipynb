{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhruvkp090/TextAsData/blob/master/Lab_0_Introduction%2C_Python_revision_%26_Regular_Expressions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text as Data Lab 0: Introduction, Python revision & Regular Expressions\n",
        "\n",
        "The aims of the lab are to:\n",
        " - Introduce you to colab, verify that you're set up with the correct python packages\n",
        " - Load textual data from Reddit as a JSON file\n",
        " - Explore the data to learn a bit about it\n",
        " - Review salient Python features, such as Counter and list comprehensions\n",
        " - Introduce regular expressions, a common tool for text matching and processing\n",
        "\n",
        "**Before you start, save a copy of this lab to your drive using \"File > Save a Copy in Drive\".** If you skip this step, you may lose progress that you have made (e.g., if you close the browser tab or your computer crashes)."
      ],
      "metadata": {
        "id": "ZlyN2JKWAxbL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab Introduction\n",
        "\n",
        "\n",
        "Colab is a cloud-based Jupyter Notebook.  It is used internally by engineers and researchers at Google and companies worldwide to prototype and share data science and ML results in an easy-to-use way. \n",
        "\n",
        "It supports:\n",
        "\n",
        "1. Text Cells with [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) formatting\n",
        "2. Code Cells\n",
        "3. Notebook stores code, output, and execution order\n",
        "4. Tab and Tab + Tab Autocomplete\n",
        "5. IPython Help Features\n",
        "6. IPython Magics (`%%`)\n",
        "\n",
        "### Additional Features\n",
        "\n",
        "- collaborative editing\n",
        "- history \n",
        "- comments\n",
        "- executed code history\n",
        "- Shift+click multiple cell selection\n",
        "- searchable code snipetts + table of contents\n",
        "- scratchpad (⌘/Ctrl + Alt + N)\n",
        "\n",
        "### Keyboard Shortcuts\n",
        "| Command | Action |\n",
        "| ---- | ----: |\n",
        "|⌘/Ctrl+Enter | Run Selected Cell |\n",
        "|Shift+Enter| Run Cell and Select Next |\n",
        "|Alt+Enter| Run cell and insert new cell|\n",
        "|⌘/Ctrl+M I | Interrupt Execution |\n",
        "\n",
        "- You can open the command Palette to see all shortcuts by going to Tools --> Command palette.\n",
        "\n",
        "### Summary of tips\n",
        "- Use TAB to autocomplete an expression. \n",
        "- You can also execute the code with a ? to get the doc strings\n",
        "- In Jupyter / Colab you can execute shell commands using `!`, example: \"!ls\" to list the current files.\n",
        "\n",
        "\n",
        "*Note:* Occasionally Colab may hang or crash (due to cloud flakiness or bad code).  You can control the execution using the Runtime menu to reboot and start fresh.  To resume where you left off you can click \"Run before\" and it will run all cells before the one currently selected.\n",
        "\n",
        "\n",
        "*Note:* You can use Colab with a cloud VM or connect to a 'local' Jupyter instance."
      ],
      "metadata": {
        "id": "mAt5xuDsLBpN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading\n",
        "\n",
        "Let's start by downloading a file containing data scraped from the online forum platform [Reddit](https://www.reddit.com/). This should take at most a few seconds to run."
      ],
      "metadata": {
        "id": "yI5XsjPanCeL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoqbvVVMAvaX",
        "outputId": "9e08a6ed-5186-437f-fca7-46104b6578da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-10 11:04:23--  https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EY_R8Y7DkrxMqXGe-zlgeNkBdJU5ZNTf8FYrN2pqDwddMA?download=1\n",
            "Resolving gla-my.sharepoint.com (gla-my.sharepoint.com)... 13.107.136.9, 13.107.138.9\n",
            "Connecting to gla-my.sharepoint.com (gla-my.sharepoint.com)|13.107.136.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=8ef1d18f92c34cbca9719efb396078d9 [following]\n",
            "--2023-01-10 11:04:24--  https://gla-my.sharepoint.com/personal/jake_lever_glasgow_ac_uk/_layouts/15/download.aspx?UniqueId=8ef1d18f92c34cbca9719efb396078d9\n",
            "Reusing existing connection to gla-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1279064 (1.2M) [application/json]\n",
            "Saving to: ‘reddit_posts.json’\n",
            "\n",
            "reddit_posts.json   100%[===================>]   1.22M  1.52MB/s    in 0.8s    \n",
            "\n",
            "2023-01-10 11:04:25 (1.52 MB/s) - ‘reddit_posts.json’ saved [1279064/1279064]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download data\n",
        "!wget -O reddit_posts.json https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EY_R8Y7DkrxMqXGe-zlgeNkBdJU5ZNTf8FYrN2pqDwddMA?download=1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration\n",
        "\n",
        "If we take a look at the contents of the data file, we see that it is encoded as an array of objects in [JSON](https://en.wikipedia.org/wiki/JSON). There are a variety of other formats used for sharing text data (e.g., [XML](https://en.wikipedia.org/wiki/XML), [Protocol Buffers](https://en.wikipedia.org/wiki/Protocol_Buffers), etc.), but JSON is among the most common these days."
      ],
      "metadata": {
        "id": "A2NGM0ZDnp65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the first 20 lines of the file - note the exclamation mark which tells Colab to run a terminal command instead of Python\n",
        "!head -n20 reddit_posts.json"
      ],
      "metadata": {
        "id": "d7homfd9ndq-",
        "outputId": "82aca946-75df-4187-cafa-7d89564225b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\r\n",
            "  {\r\n",
            "    \"subreddit\": \"Soda\",\r\n",
            "    \"title\": \"Anyone tried Irn Bru?\",\r\n",
            "    \"score\": 8,\r\n",
            "    \"id\": \"ou5yp1\",\r\n",
            "    \"author\": \"jackibhoy\",\r\n",
            "    \"body\": \"It\\u2019s a Scottish drink and it\\u2019s banned some countries and I was wondering if anyone here has tried it. It has quite a unique taste and it\\u2019s not something you\\u2019d forget quickly. You either love it or hate it I think.\"\r\n",
            "  },\r\n",
            "  {\r\n",
            "    \"subreddit\": \"Soda\",\r\n",
            "    \"title\": \"What is the worst or some of the worst sodas you have drunk\",\r\n",
            "    \"score\": 3,\r\n",
            "    \"id\": \"nt40i4\",\r\n",
            "    \"author\": \"EpicEllis2004\",\r\n",
            "    \"body\": \"The absolute worst soda ive ever had that i can remember is probaly the new mystery fanta or watermelon+strawberry tango some other ones include mango coke, sugar free irn bru (but xtra is nice)\"\r\n",
            "  },\r\n",
            "  {\r\n",
            "    \"subreddit\": \"tea\",\r\n",
            "    \"title\": \"I once had a box of tea that I believe was Scottish Highland black tea. Can anyone recommend me a tea along those lines?\",\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data provided by online APIs, such as the [Reddit API](https://www.reddit.com/dev/api/), are usually available in JSON. For this lab, we use a simplified version of the Reddit data, aggregating posts across several subreddits (i.e., sub-forums) and using just a handful of salient fields for each post. The data file consists of some structured data (`subreddit`, `score`, `id`, and `author`), and two unstructured text fields (`title` and `body`)."
      ],
      "metadata": {
        "id": "BuBN2-KoGuep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's load the data into Python so we can work with it. The [json](https://docs.python.org/3/library/json.html) package in the Python standard library makes loading the data very easy."
      ],
      "metadata": {
        "id": "RcydjzEdGx_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data into Python\n",
        "import json\n",
        "with open('reddit_posts.json', 'rt') as fin:\n",
        "  reddit_posts = json.load(fin)"
      ],
      "metadata": {
        "id": "iRz19a-7A4iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python's JSON parser provides the data as a `list` of `dict` objects. You should already be familiar with these classes; if not, you can refer to [Python's data structures documentation](https://docs.python.org/3/tutorial/datastructures.html).\n",
        "\n",
        "Let's look at the types of data available provided and some basic information."
      ],
      "metadata": {
        "id": "GKe3TU9HHnrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigate the structure of the data\n",
        "print('type(reddit_posts) =', type(reddit_posts))\n",
        "print('len(reddit_posts) =', len(reddit_posts))\n",
        "print('type(reddit_posts[0]) =', type(reddit_posts[0]))\n",
        "print('reddit_posts[0].keys() =', reddit_posts[0].keys())\n",
        "print('reddit_posts[0][\"title\"] =', reddit_posts[0][\"title\"])"
      ],
      "metadata": {
        "id": "xinvnfVGBKoL",
        "outputId": "1bf56ca3-7f75-4b60-c546-42b52a36a9a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type(reddit_posts) = <class 'list'>\n",
            "len(reddit_posts) = 2000\n",
            "type(reddit_posts[0]) = <class 'dict'>\n",
            "reddit_posts[0].keys() = dict_keys(['subreddit', 'title', 'score', 'id', 'author', 'body'])\n",
            "reddit_posts[0][\"title\"] = Anyone tried Irn Bru?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there are 2000 posts in the dataset. It's always important to understand the data you're working with, so let's see which subreddits these posts are from.\n",
        "\n",
        "We could write code to loop through each of the posts and keep a running count of the number of posts in each subreddit:\n",
        "\n",
        "```python\n",
        "# The code that uses Counter below essentially does this:\n",
        "subreddit_counts = {}\n",
        "for post in reddit_posts:\n",
        "  subreddit = post['subreddit']\n",
        "  if subreddit not in subreddit_counts:\n",
        "    subreddit_counts[subreddit] = 0\n",
        "  subreddit_counts[subreddit] += 1\n",
        "subreddit_counts\n",
        "```\n",
        "\n",
        "Python provides a convienent [`Counter`](https://docs.python.org/3/library/collections.html#collections.Counter) class to count values like this, so we'll use that instead. We can use a [Generator Expression](https://docs.python.org/3/reference/expressions.html#generator-expressions) to get the subreddit from each post and let `Counter` count how many times each subreddit appears."
      ],
      "metadata": {
        "id": "ku6Iri8SKikQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of times each subreddit appears in this dataset\n",
        "from collections import Counter\n",
        "Counter(post['subreddit'] for post in reddit_posts)"
      ],
      "metadata": {
        "id": "o8_WlxMrKNWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there are 9 subreddits covered by the dataset, mostly about beverages and gaming. The Soda subreddit is the least common (174 posts) and the NintendoSwitch subreddit is the most common (249 posts).\n",
        "\n",
        "**Exercise:** Can you find the user with the most posts and how many posts they have? (Hint: `Counter` provides a function that will help you find the item with the highest count, without needing to look through all the counts manually. You can find this in the documentation.)"
      ],
      "metadata": {
        "id": "PZmd8evUNxmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "metadata": {
        "id": "b9imZr5MK3nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should find that AutoModerator has the most number of posts, with 5.\n",
        "\n",
        "AutoModerator sounds like it may not be a human user, so let's take a look at their posts. There are several ways to do this filtering. One of the most concise is to use a [List Comprehension](https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions), so we'll do that here:"
      ],
      "metadata": {
        "id": "nujmWnKnPHUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[ post for post in reddit_posts if post['author'] == 'AutoModerator' ]"
      ],
      "metadata": {
        "id": "83yPQ-tPPSms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed, through qualitatively inspecting of AutoModerator's posts, they appear to be automatially generated.\n",
        "\n",
        "Depending on your application, you may want to filter out such posts. For instance, if you were trying to measure public sentiment about a product, you are probably only interested in human users. You could filter out auto-generated posts by manually checking each post, but this becomes impractical as the size of your collection grows. Later in this course we will cover text classification techniques, which could be used to automatically label a large number of posts given manally-labeled training data.\n",
        "\n"
      ],
      "metadata": {
        "id": "iS6VaixxH2MZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you find out anything else interesting from the dataset by inspecting the data?"
      ],
      "metadata": {
        "id": "d2m3Fua5J9aA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this cell to explore the dataset. (Feel free to make other cells as well.)"
      ],
      "metadata": {
        "id": "czSDK1yUKFst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular Expressions\n",
        "\n",
        "[Regular Expressions](https://en.wikipedia.org/wiki/Regular_expression) (often abbreviated as regex or regexp) are a common tool for pattern matching in text. Python provides regular expressions in the [`re`](https://docs.python.org/3/library/re.html) package.\n",
        "\n",
        "Regular expressions can get very complicated, but it is valuable to be familiar with them. This portion of the lab provides a basic introduction to regex and provides links to further details if you want to learn more."
      ],
      "metadata": {
        "id": "6ZZNGQhoVDqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Motivating Example\n",
        "\n",
        "Let's say you want to find all posts that mention [Irn-Bru](https://en.wikipedia.org/wiki/Irn-Bru). One option would be to use the string contains operator (`in`):"
      ],
      "metadata": {
        "id": "W7NC0yTaWKvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[ p for p in reddit_posts if 'Irn-Bru' in p['title'] or 'Irn-Bru' in p['body'] ]"
      ],
      "metadata": {
        "id": "IB5M4O4ITQ6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm, nothing matches? Didn't we see the first post mentioned Irn-Bru?"
      ],
      "metadata": {
        "id": "qFHHlZktYNON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reddit_posts[0]"
      ],
      "metadata": {
        "id": "uqtxBz8PYMmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indeed so, but they stylized it as \"Irn Bru\" rather than \"Irn-Bru\". There's probably other ways people might write it too, like IrnBru, Irnbru, etc. We could come up with a list of possiblities and control for different casing (like the code below), but we still might miss some. There's a simpler way using regular expressions.\n",
        "\n",
        "```python\n",
        "match_strings = ['irn-bru', 'irn bru', 'irnbru']\n",
        "[ p for p in reddit_posts if any(m in p['title'].lower() or m in p['body'].lower() for m in match_strings) ]\n",
        "```\n",
        "\n",
        "### Filtering with Regular Expressions\n",
        "\n",
        "A regular expression defines a pattern to match in text as a string. Most characters (letters, numbers) in a pattern match themelves. Some perform special functions, like making the precious character optional or allowing multiple characters to match. For instances:\n",
        " - \"`.`\" matches any character.\n",
        " - \"`?`\" makes the precious character optional.\n",
        "\n",
        "With this, we can define the regular expression `\"irn.?bru\"`, which will match `irn` and `bru` with any character (or no character) between them. An option allows case insensitive matching.\n",
        "\n",
        "We can use regular expressions in python by first importing the `re` package and then compling our pattern."
      ],
      "metadata": {
        "id": "7WTMGfb8Yazn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "pattern = re.compile(r'irn.?bru', re.I) # re.I makes the pattern case insensitive\n",
        "# NB: it's usually a good idea to define regex using raw strings (r'') to avoid string escaping within the expression."
      ],
      "metadata": {
        "id": "zdwtfULaY0ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pattern object can do all sorts of things. Most commonly, you will use the `search` function, which finds and returns the first place that the pattern matches a string."
      ],
      "metadata": {
        "id": "HdPqbd3niIzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "match = pattern.search(\"Anyone tried Irn Bru?\")\n",
        "match"
      ],
      "metadata": {
        "id": "IAnKSfq5iN4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The match object gives the character offsets of the match (`match.span`) and the text itself that matches (`match.group(0)`).\n",
        "\n",
        "If no match is found, `search` returns `None`, which evaluates as `False` when it's used in an `if` statement. This allows it to be easily used for filtering data. Using regular expressions, we find 6 posts about Irn-Bru."
      ],
      "metadata": {
        "id": "tYbnVJPXiglC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[ p for p in reddit_posts if pattern.search(p['title']) or pattern.search(p['body']) ]"
      ],
      "metadata": {
        "id": "PlxoWsLShHwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there are a variety of ways that people express Irn-Bru.\n",
        "\n",
        "**Exercise:** Can you write code that finds all the ways people express Irn-Bru in the dataset (e.g., \"Irn-Bru\", \"IRN BRU\", etc.)? Hint: you probably need to use the [`findall` function](https://docs.python.org/3/library/re.html#re.findall) with the `pattern` already defined above."
      ],
      "metadata": {
        "id": "QNcswjeikHz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "metadata": {
        "id": "J8-GabEslnMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(You should find that \"Irn Bru\" appears 6 times, \"IRN-BRU\" appears twice, \"IRN BRU\" once, and \"irn bru\" once.)"
      ],
      "metadata": {
        "id": "6Bq4NihLnRqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try to find some years mentioned in the text of the documents. you'll need to define a new pattern. You might find that a [regular expressions cheatsheet](https://cheatography.com/davechild/cheat-sheets/regular-expressions/) is helpful so you can look up the pattern for `digit`.\n",
        "\n",
        "**Exercise:** Find all 21st-century years (4 digit numbers starting with '20') in the title and bodies of the posts. What is the most common?"
      ],
      "metadata": {
        "id": "fUClndGDdg0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your answer here"
      ],
      "metadata": {
        "id": "NCJ8HvwMdhrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should find that the digits `2016` appears 35 times across the posts.\n",
        "\n",
        "Now, a question: do you think all of those 4 digit numbers are actually years in the text. Could they be anything else?"
      ],
      "metadata": {
        "id": "93uo_7WHeZX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Resources\n",
        "\n",
        "These examples only scratches the surface of the capacities of regular expressions. We refer you to these resources for further details.\n",
        "\n",
        " - [RegExr](https://regexr.com/) -- Interactively build and evaluation regular expressions in a GUI. This can be helpful when trying to build a tricky regex or figure out why it's not matching what you want it to.\n",
        " - [RegexOne](https://regexone.com/) -- A detailed and interactive regular epxression tutorial\n",
        " - [Python's `re` documentation](https://docs.python.org/3/library/re.html) -- Provides details about both regex syntax and Python's regex API"
      ],
      "metadata": {
        "id": "a5e4crdKVFSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab Summary\n",
        "\n",
        "In this lab you:\n",
        " - Started using Colab\n",
        " - Loaded textual data from Reddit as a JSON file\n",
        " - Explored the data to learn a bit about it\n",
        " - Reviewed salient Python features, such as Counter and list comprehensions\n",
        " - Explored using regular expressions in Python\n",
        "\n",
        "**Please remember to submit your completed lab on and feedback form on Moodle.**"
      ],
      "metadata": {
        "id": "hIeO1UeINAjL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional Bonus\n",
        "\n",
        "Play with [ChatGPT](https://chat.openai.com/). You will have to make a free account to use it. And sometimes it is too busy and you'll need to come back later.\n",
        "\n",
        "**Task:** Try to get ChatGPT to say something factually incorrect."
      ],
      "metadata": {
        "id": "lQa3CLJveFMW"
      }
    }
  ]
}